# Issue: Create end-to-end test script

## Overview
# Issue #006.1: Create end-to-end test script

## Overview
Create a comprehensive end-to-end test script that validates the complete PRD workflow using all implemented validation, error handling, and recovery mechanisms.

## Files to Modify
1. `.claude/scripts/cccc/e2e-workflow-test.sh` (new)

## Implementation Sketch

```bash
#!/bin/bash
# e2e-workflow-test.sh - End-to-end PRD workflow testing

# Test configuration
TEST_PRD_BASE="e2e-test"
TEST_DIR=$(mktemp -d)
ORIGINAL_DIR=$(pwd)
TOTAL_TESTS=0
PASSED_TESTS=0
FAILED_TESTS=0

# Source all validation and recovery functions
source_test_dependencies() {
    local script_dir="$(dirname "$0")"
    
    if [[ -f "$script_dir/validate-prd.sh" ]]; then
        source "$script_dir/validate-prd.sh"
        echo "‚úÖ Loaded validation functions"
    else
        echo "‚ùå Missing validation functions"
        return 1
    fi
    
    if [[ -f "$script_dir/error-recovery.sh" ]]; then
        source "$script_dir/error-recovery.sh"
        echo "‚úÖ Loaded recovery functions"
    else
        echo "‚ùå Missing recovery functions"
        return 1
    fi
}

# Setup comprehensive test environment
setup_e2e_environment() {
    echo "üîß Setting up end-to-end test environment: $TEST_DIR"
    cd "$TEST_DIR"
    
    # Create CCCC directory structure
    mkdir -p {.cccc/{prds,epics},.claude/{commands/cccc/prd,scripts/cccc}}
    
    # Copy command files
    cp -r "$ORIGINAL_DIR/.claude/commands/cccc/prd"/* ".claude/commands/cccc/prd/"
    cp -r "$ORIGINAL_DIR/.claude/scripts/cccc"/* ".claude/scripts/cccc/"
    
    # Make scripts executable
    chmod +x .claude/scripts/cccc/*.sh
    
    echo "‚úÖ Test environment ready"
    return 0
}

# Test helper functions
run_test() {
    local test_name="$1"
    local test_function="$2"
    
    echo ""
    echo "üß™ Running test: $test_name"
    echo "=================================================="
    
    ((TOTAL_TESTS++))
    
    if $test_function; then
        echo "‚úÖ PASSED: $test_name"
        ((PASSED_TESTS++))
        return 0
    else
        echo "‚ùå FAILED: $test_name"
        ((FAILED_TESTS++))
        return 1
    fi
}

# Test 1: Valid PRD Creation
test_valid_prd_creation() {
    local test_prd="${TEST_PRD_BASE}-valid"
    
    # Test PRD creation
    if ! .claude/commands/cccc/prd/new.md "$test_prd" >/dev/null 2>&1; then
        echo "‚ùå PRD creation failed"
        return 1
    fi
    
    # Validate created PRD
    local prd_path=".cccc/prds/${test_prd}.md"
    
    if [[ ! -f "$prd_path" ]]; then
        echo "‚ùå PRD file not created: $prd_path"
        return 1
    fi
    
    if ! validate_yaml_frontmatter "$prd_path"; then
        echo "‚ùå PRD has invalid frontmatter"
        return 1
    fi
    
    echo "‚úÖ Valid PRD created and validated"
    return 0
}

# Test 2: Invalid PRD Name Handling
test_invalid_prd_name() {
    local invalid_names=("spaces in name" "special@chars!" "too-long-name-that-exceeds-the-fifty-character-limit-defined-in-validation" "")
    
    for name in "${invalid_names[@]}"; do
        if .claude/commands/cccc/prd/new.md "$name" >/dev/null 2>&1; then
            echo "‚ùå Invalid name '$name' was accepted"
            return 1
        fi
    done
    
    echo "‚úÖ All invalid PRD names properly rejected"
    return 0
}

# Test 3: PRD Overwrite Protection
test_prd_overwrite_protection() {
    local test_prd="${TEST_PRD_BASE}-overwrite"
    
    # Create initial PRD
    .claude/commands/cccc/prd/new.md "$test_prd" >/dev/null 2>&1
    
    # Add custom content to PRD
    echo -e "\n## Custom Section\nThis is custom content." >> ".cccc/prds/${test_prd}.md"
    
    # Attempt to recreate (should prompt for confirmation)
    # Simulate "no" response
    echo "no" | .claude/commands/cccc/prd/new.md "$test_prd" >/dev/null 2>&1
    
    # Check that custom content still exists
    if ! grep -q "Custom Section" ".cccc/prds/${test_prd}.md"; then
        echo "‚ùå PRD was overwritten without confirmation"
        return 1
    fi
    
    echo "‚úÖ PRD overwrite protection working"
    return 0
}

# Test 4: Valid PRD Parsing
test_valid_prd_parsing() {
    local test_prd="${TEST_PRD_BASE}-parsing"
    
    # Create test PRD with proper structure
    create_test_prd_for_parsing "$test_prd"
    
    # Parse PRD
    if ! .claude/commands/cccc/prd/parse.md "$test_prd" >/dev/null 2>&1; then
        echo "‚ùå PRD parsing failed"
        return 1
    fi
    
    # Validate epic was created
    local epic_dir=".cccc/epics/$test_prd"
    if [[ ! -d "$epic_dir" ]]; then
        echo "‚ùå Epic directory not created"
        return 1
    fi
    
    if [[ ! -f "$epic_dir/epic.md" ]]; then
        echo "‚ùå Epic file not created"
        return 1
    fi
    
    # Check for task files
    local task_count=$(ls -1 "$epic_dir"/[0-9][0-9][0-9].md 2>/dev/null | wc -l)
    if [[ $task_count -eq 0 ]]; then
        echo "‚ùå No task files generated"
        return 1
    fi
    
    echo "‚úÖ PRD parsed successfully ($task_count tasks generated)"
    return 0
}

# Test 5: Invalid PRD Parsing Handling
test_invalid_prd_parsing() {
    # Test parsing nonexistent PRD
    if .claude/commands/cccc/prd/parse.md "nonexistent-prd" >/dev/null 2>&1; then
        echo "‚ùå Nonexistent PRD parsing should fail"
        return 1
    fi
    
    # Create PRD with invalid frontmatter
    local invalid_prd="${TEST_PRD_BASE}-invalid"
    cat > ".cccc/prds/${invalid_prd}.md" <<'EOF'
---
name: "Missing Required Fields"
# Missing status, created, version
---
# Invalid PRD
Content without proper structure.
EOF
    
    if .claude/commands/cccc/prd/parse.md "$invalid_prd" >/dev/null 2>&1; then
        echo "‚ùå Invalid PRD parsing should fail"
        return 1
    fi
    
    echo "‚úÖ Invalid PRD parsing properly rejected"
    return 0
}

# Test 6: Error Recovery Mechanisms
test_error_recovery() {
    local test_prd="${TEST_PRD_BASE}-recovery"
    
    # Create a PRD that will fail during parsing (simulate corruption)
    create_test_prd_for_parsing "$test_prd"
    
    # Create partial epic directory to simulate failed parsing
    mkdir -p ".cccc/epics/$test_prd"
    echo "partial content" > ".cccc/epics/$test_prd/partial.md"
    
    # Run recovery
    if ! .claude/scripts/cccc/error-recovery.sh prd-parsing "$test_prd" >/dev/null 2>&1; then
        echo "‚ùå Error recovery failed"
        return 1
    fi
    
    # Check that partial epic was cleaned up
    if [[ -d ".cccc/epics/$test_prd" ]]; then
        echo "‚ùå Partial epic directory not cleaned up"
        return 1
    fi
    
    echo "‚úÖ Error recovery working correctly"
    return 0
}

# Test 7: System State Validation
test_system_validation() {
    # Create some temporary files to test cleanup
    touch .cccc/temp.tmp .cccc/backup.bak
    
    # Run system validation
    echo "yes" | .claude/scripts/cccc/error-recovery.sh validate-state >/dev/null 2>&1
    
    # Check that temp files were cleaned
    if [[ -f ".cccc/temp.tmp" || -f ".cccc/backup.bak" ]]; then
        echo "‚ùå Temporary files not cleaned up"
        return 1
    fi
    
    echo "‚úÖ System validation working correctly"
    return 0
}

# Test 8: Complete Workflow Integration
test_complete_workflow() {
    local test_prd="${TEST_PRD_BASE}-complete"
    
    # Step 1: Create PRD
    if ! .claude/commands/cccc/prd/new.md "$test_prd" >/dev/null 2>&1; then
        echo "‚ùå Workflow step 1 (creation) failed"
        return 1
    fi
    
    # Step 2: Enhance PRD with proper content
    create_test_prd_for_parsing "$test_prd"
    
    # Step 3: Parse PRD
    if ! .claude/commands/cccc/prd/parse.md "$test_prd" >/dev/null 2>&1; then
        echo "‚ùå Workflow step 3 (parsing) failed"
        return 1
    fi
    
    # Step 4: Validate results
    local epic_dir=".cccc/epics/$test_prd"
    local prd_path=".cccc/prds/${test_prd}.md"
    
    if [[ ! -f "$prd_path" || ! -d "$epic_dir" ]]; then
        echo "‚ùå Workflow validation failed"
        return 1
    fi
    
    # Step 5: Test workflow validation script
    if ! .claude/scripts/cccc/test-prd-workflow.sh >/dev/null 2>&1; then
        echo "‚ùå Workflow validation script failed"
        return 1
    fi
    
    echo "‚úÖ Complete workflow integration successful"
    return 0
}

# Helper function to create test PRD with proper structure
create_test_prd_for_parsing() {
    local prd_name="$1"
    local prd_path=".cccc/prds/${prd_name}.md"
    
    cat > "$prd_path" <<EOF
---
name: "$prd_name"
status: "draft"
created: "2025-08-28T02:31:24Z"
updated: "2025-08-28T02:31:24Z"
version: "1.0.0"
author: "CCCC Test System"
type: "test"
priority: "medium"
estimated_effort: "2 hours"
github: "[Test PRD]"
---

# $prd_name

## Problem Statement
This is a test PRD created for end-to-end workflow validation.

## Solution Overview
Implement a test solution that demonstrates all PRD parsing capabilities.

## User Stories

### US001: Test User Story
**As a** test user
**I want** to validate the PRD workflow
**So that** I can ensure the system works correctly

**Acceptance Criteria:**
- PRD creation works properly
- PRD parsing generates epic
- Error handling works correctly
EOF
}

# Performance benchmarking
benchmark_operations() {
    echo ""
    echo "üìä Performance Benchmarking"
    echo "=================================================="
    
    local prd_name="${TEST_PRD_BASE}-benchmark"
    
    # Benchmark PRD creation
    local start_time=$(date +%s%N)
    .claude/commands/cccc/prd/new.md "$prd_name" >/dev/null 2>&1
    local end_time=$(date +%s%N)
    local creation_time=$(( (end_time - start_time) / 1000000 ))
    
    # Benchmark PRD parsing
    create_test_prd_for_parsing "$prd_name"
    start_time=$(date +%s%N)
    .claude/commands/cccc/prd/parse.md "$prd_name" >/dev/null 2>&1
    end_time=$(date +%s%N)
    local parsing_time=$(( (end_time - start_time) / 1000000 ))
    
    echo "‚è±Ô∏è PRD Creation: ${creation_time}ms"
    echo "‚è±Ô∏è PRD Parsing: ${parsing_time}ms"
    
    # Check performance targets
    local performance_issues=0
    if [[ $creation_time -gt 5000 ]]; then
        echo "‚ö†Ô∏è PRD creation slower than target (5s)"
        ((performance_issues++))
    fi
    
    if [[ $parsing_time -gt 10000 ]]; then
        echo "‚ö†Ô∏è PRD parsing slower than target (10s)"
        ((performance_issues++))
    fi
    
    if [[ $performance_issues -eq 0 ]]; then
        echo "‚úÖ All performance targets met"
        return 0
    else
        echo "‚ö†Ô∏è $performance_issues performance issues detected"
        return 1
    fi
}

# Cleanup test environment
cleanup_e2e_environment() {
    echo ""
    echo "üßπ Cleaning up test environment..."
    cd "$ORIGINAL_DIR"
    rm -rf "$TEST_DIR"
    echo "‚úÖ Test environment cleaned up"
}

# Main test execution
main() {
    echo "üöÄ Starting End-to-End PRD Workflow Tests"
    echo "=================================================="
    echo "Test Environment: $TEST_DIR"
    echo ""
    
    # Setup
    source_test_dependencies || exit 1
    setup_e2e_environment || exit 1
    
    # Run all tests
    run_test "Valid PRD Creation" test_valid_prd_creation
    run_test "Invalid PRD Name Handling" test_invalid_prd_name
    run_test "PRD Overwrite Protection" test_prd_overwrite_protection
    run_test "Valid PRD Parsing" test_valid_prd_parsing
    run_test "Invalid PRD Parsing Handling" test_invalid_prd_parsing
    run_test "Error Recovery Mechanisms" test_error_recovery
    run_test "System State Validation" test_system_validation
    run_test "Complete Workflow Integration" test_complete_workflow
    
    # Performance benchmarking
    benchmark_operations
    local benchmark_result=$?
    
    # Final results
    echo ""
    echo "üìã End-to-End Test Summary"
    echo "=================================================="
    echo "Total Tests: $TOTAL_TESTS"
    echo "Passed: $PASSED_TESTS"
    echo "Failed: $FAILED_TESTS"
    echo "Performance: $([ $benchmark_result -eq 0 ] && echo "‚úÖ PASSED" || echo "‚ö†Ô∏è ISSUES")"
    echo ""
    
    # Cleanup
    cleanup_e2e_environment
    
    if [[ $FAILED_TESTS -eq 0 && $benchmark_result -eq 0 ]]; then
        echo "üéâ All end-to-end tests PASSED!"
        echo "‚úÖ PRD workflow is fully validated and ready for production"
        return 0
    else
        echo "üí• End-to-end tests FAILED"
        echo "‚ùå Issues found: $FAILED_TESTS test failures, performance issues: $benchmark_result"
        return 1
    fi
}

# Run main function if script is executed directly
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi
```

## Acceptance Criteria
- [ ] Script tests complete PRD creation workflow
- [ ] Script tests complete PRD parsing workflow
- [ ] Script tests error handling and recovery mechanisms
- [ ] Script tests system state validation
- [ ] Script includes performance benchmarking
- [ ] Script provides comprehensive test reporting
- [ ] Script handles test environment setup/cleanup automatically
- [ ] Script validates integration of all components
- [ ] Script returns proper exit codes
- [ ] Script can be run independently for CI/CD integration

## Dependencies
- All previous issues must be complete (001.1 through 005.2)

## Definition of Done
- [ ] Code implemented according to implementation sketch
- [ ] All acceptance criteria met
- [ ] Script follows CCCC bash patterns and standards
- [ ] Comprehensive end-to-end validation of entire workflow
- [ ] Ready for performance benchmarking enhancements (Issue #006.2)\n\n---\nDepends on #35\nDepends on #36\nDepends on #37\nDepends on #38\nDepends on #39\nDepends on #40\nDepends on #41\nDepends on #42

## Comments Processing Summary
2025-08-28T11:37:52Z: Updated from platform

### Structured Updates Applied:


**jeunesse.paulien** (2025-08-28T04:42:34.395Z):
mentioned in issue #46


---
*Last updated from platform: 2025-08-28T11:37:52Z*
